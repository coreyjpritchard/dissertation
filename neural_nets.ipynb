{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc71b4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 11:09:52.438051: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747303792.456073  526879 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747303792.461251  526879 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-15 11:09:52.478997: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "# import Input layer\n",
    "from keras.layers import Input, Dense, LSTM, Dropout, BatchNormalization, Masking, LayerNormalization, Bidirectional, Conv1D, GlobalAvgPool1D, Attention, Activation, MaxPool1D, GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.losses import Huber\n",
    "from keras.optimizers import Adam\n",
    "#from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# traint test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfac0846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for gpus\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20901a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SPY: possibly delisted; no price data found  (period=30y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Log Return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Open, High, Low, Close, Adj Close, Volume, Log Return]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_str = \"SPY\"\n",
    "yf_ticker = yf.Ticker(ticker_str)\n",
    "yf_data = yf_ticker.history(period=\"30y\")\n",
    "\n",
    "yf_data[\"Log Return\"] = np.log(yf_data[\"Close\"] / yf_data[\"Close\"].shift(1))\n",
    "yf_data = yf_data[1:]\n",
    "\n",
    "yf_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df5cd648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "yf_data[\"Log Return Sq\"] = yf_data[\"Log Return\"] ** 2\n",
    "lookback = 60\n",
    "\n",
    "num_rolling = [15, 30, 60, 180]\n",
    "for i in num_rolling:\n",
    "    yf_data[f\"Rolling Mean {i}\"] = yf_data[\"Log Return\"].rolling(i).mean()\n",
    "    yf_data[f\"Rolling Std {i}\"] = yf_data[\"Log Return\"].rolling(i).std()\n",
    "    yf_data[f\"Rolling Skew {i}\"] = yf_data[\"Log Return\"].rolling(i).skew()\n",
    "    yf_data[f\"Rolling Kurt {i}\"] = yf_data[\"Log Return\"].rolling(i).kurt()\n",
    "\n",
    "    yf_data[f\"Rolling Vol Mean {i}\"] = yf_data[\"Log Return Sq\"].rolling(i).mean()\n",
    "    yf_data[f\"Rolling Vol Std {i}\"] = yf_data[\"Log Return Sq\"].rolling(i).std()\n",
    "    yf_data[f\"Rolling Vol Skew {i}\"] = yf_data[\"Log Return Sq\"].rolling(i).skew()\n",
    "    yf_data[f\"Rolling Vol Kurt {i}\"] = yf_data[\"Log Return Sq\"].rolling(i).kurt()\n",
    "\n",
    "\n",
    "\n",
    "high_low = yf_data[\"High\"] - yf_data[\"Low\"]\n",
    "high_close = (yf_data[\"High\"] - yf_data[\"Close\"].shift()).abs()\n",
    "low_close = (yf_data[\"Low\"]  - yf_data[\"Close\"].shift()).abs()\n",
    "tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "yf_data[\"ATR 14\"] = tr.rolling(14).mean()\n",
    "\n",
    "mid = yf_data[\"Close\"].rolling(20).mean()\n",
    "std = yf_data[\"Close\"].rolling(20).std()\n",
    "yf_data[\"BB Width\"] = (mid + 2*std - (mid - 2*std)) / mid\n",
    "\n",
    "delta = yf_data[\"Close\"].diff()\n",
    "up = delta.clip(lower=0)\n",
    "down = -delta.clip(upper=0)\n",
    "ema_up = up.ewm(span=14).mean()\n",
    "ema_dn = down.ewm(span=14).mean()\n",
    "yf_data[\"RSI 14\"] = 100 - (100 / (1 + ema_up/ema_dn))\n",
    "\n",
    "# close z score in recent window\n",
    "yf_data[\"Z Score\"] = (yf_data[\"Close\"] - yf_data[\"Close\"].rolling(lookback).mean()) / yf_data[\"Close\"].rolling(lookback).std()\n",
    "\n",
    "yf_data = yf_data[max(num_rolling):]             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6262a400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Log Return',\n",
       "       'Log Return Sq', 'Rolling Mean 15', 'Rolling Std 15', 'Rolling Skew 15',\n",
       "       'Rolling Kurt 15', 'Rolling Vol Mean 15', 'Rolling Vol Std 15',\n",
       "       'Rolling Vol Skew 15', 'Rolling Vol Kurt 15', 'Rolling Mean 30',\n",
       "       'Rolling Std 30', 'Rolling Skew 30', 'Rolling Kurt 30',\n",
       "       'Rolling Vol Mean 30', 'Rolling Vol Std 30', 'Rolling Vol Skew 30',\n",
       "       'Rolling Vol Kurt 30', 'Rolling Mean 60', 'Rolling Std 60',\n",
       "       'Rolling Skew 60', 'Rolling Kurt 60', 'Rolling Vol Mean 60',\n",
       "       'Rolling Vol Std 60', 'Rolling Vol Skew 60', 'Rolling Vol Kurt 60',\n",
       "       'Rolling Mean 180', 'Rolling Std 180', 'Rolling Skew 180',\n",
       "       'Rolling Kurt 180', 'Rolling Vol Mean 180', 'Rolling Vol Std 180',\n",
       "       'Rolling Vol Skew 180', 'Rolling Vol Kurt 180', 'ATR 14', 'BB Width',\n",
       "       'RSI 14', 'Z Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ca77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"Log Return\",\n",
    "    \"Log Return Sq\",\n",
    "    # \"ATR 14\",\n",
    "    # \"BB Width\",\n",
    "    # \"RSI 14\",\n",
    "    # \"Z Score\"\n",
    "]\n",
    "\n",
    "\n",
    "features += [f\"Rolling Mean {i}\" for i in num_rolling]\n",
    "features += [f\"Rolling Std {i}\" for i in num_rolling]\n",
    "features += [f\"Rolling Skew {i}\" for i in num_rolling]\n",
    "features += [f\"Rolling Kurt {i}\" for i in num_rolling]\n",
    "\n",
    "features += [f\"Rolling Vol Mean {i}\" for i in num_rolling]\n",
    "features += [f\"Rolling Vol Std {i}\" for i in num_rolling]\n",
    "features += [f\"Rolling Vol Skew {i}\" for i in num_rolling]\n",
    "features += [f\"Rolling Vol Kurt {i}\" for i in num_rolling]\n",
    "\n",
    "# features += [f\"VolVol {i}\" for i in num_rolling]\n",
    "# features += [f\"Vol Mean {i}\" for i in num_rolling]\n",
    "#features += [\"Vol Mean\", \"Vol Vol\"]\n",
    "\n",
    "\n",
    "# features += [f\"Log Return Lag {i}\" for i in range(1, num_lags + 1)]\n",
    "# features += [f\"Log Return Sq Lag {i}\" for i in range(1, num_lags + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4bf4a03",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'sqrt' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#target_scaler = MinMaxScaler()\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreg_y1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m yf_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLog Return\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreg_y2\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLog Return Sq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m df[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'sqrt' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "df = yf_data[features].copy()\n",
    "\n",
    "#target_scaler = MinMaxScaler()\n",
    "df[\"reg_y1\"] = yf_data[\"Log Return\"].copy().shift(-1)\n",
    "df[\"reg_y2\"] = np.sqrt(\"Log Return Sq\").shift(-1)\n",
    "df = df[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a607cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target class\n",
       "count           7365\n",
       "unique             2\n",
       "top                0\n",
       "freq            4420"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # qcut instad\n",
    "#num_classes = 3\n",
    "q = [0, 0.6, 1]\n",
    "num_classes = len(q) - 1\n",
    "\n",
    "#class_target_scaler = StandardScaler()\n",
    "#class_target_scaler.fit_transform(yf_data[\"Log Return Sq\"].values.reshape(-1, 1))\n",
    "\n",
    "yf_data[\"Vol\"] = yf_data[\"Log Return\"].rolling(5).std()\n",
    "\n",
    "df[\"target reg\"] = yf_data[\"Vol\"].copy().shift(-1)\n",
    "\n",
    "df[\"target class\"] = pd.qcut(yf_data[\"Vol\"].copy(), q, labels=[i for i in range(num_classes)]).shift(-1)\n",
    "\n",
    "\n",
    "df = df[:-1]\n",
    "\n",
    "target_type = \"class\"\n",
    "\n",
    "if target_type == \"reg\":\n",
    "    #targets = [\"reg_y1\", \"reg_y2\"]\n",
    "    targets = [\"target reg\"] # vol\n",
    "\n",
    "else:\n",
    "    targets = [\"target class\"]\n",
    "\n",
    "df[targets].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8142fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_437505/3923377994.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df.groupby(\"target class\")[\"target reg\"].describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4420.0</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.005812</td>\n",
       "      <td>0.007554</td>\n",
       "      <td>0.009631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2945.0</td>\n",
       "      <td>0.016162</td>\n",
       "      <td>0.008534</td>\n",
       "      <td>0.009633</td>\n",
       "      <td>0.011318</td>\n",
       "      <td>0.013650</td>\n",
       "      <td>0.017760</td>\n",
       "      <td>0.092075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count      mean       std       min       25%       50%  \\\n",
       "target class                                                             \n",
       "0             4420.0  0.005810  0.002128  0.000425  0.004149  0.005812   \n",
       "1             2945.0  0.016162  0.008534  0.009633  0.011318  0.013650   \n",
       "\n",
       "                   75%       max  \n",
       "target class                      \n",
       "0             0.007554  0.009631  \n",
       "1             0.017760  0.092075  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"target class\")[\"target reg\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d4a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.07331132e-04, 1.35009754e-05, 1.73489851e-05, ...,\n",
       "       1.05709923e-03, 4.33258734e-05, 1.63127929e-06])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf_data[\"Log Return Sq\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2d23e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target class\n",
       "0               4420\n",
       "1               2945\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[targets].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87f0052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644edfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(df[\"Volatility\"], bins=100)\n",
    "# colour x axis by class\n",
    "# plt.hist(df[df[\"target class\"] == 0][\"reg_y1\"], bins=50, alpha=0.5, density=True)\n",
    "# plt.hist(df[df[\"target class\"] == 1][\"reg_y1\"], bins=50, alpha=0.5, density=True)\n",
    "\n",
    "if target_type == \"reg\":\n",
    "    for i in np.unique(df[\"target class\"]):\n",
    "        plt.hist(df[df[\"target class\"] == i][\"reg_y1\"], bins=100, alpha=0.5, density=False)\n",
    "    plt.title(\"Log Return Distribution Classificaiton\")\n",
    "    plt.xlabel(\"y1\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend([f\"Class {i}\" for i in np.unique(df[\"target class\"])])\n",
    "    plt.show()\n",
    "\n",
    "    for i in np.unique(df[\"target class\"]):\n",
    "        plt.hist(df[df[\"target class\"] == i][\"reg_y2\"], bins=100, alpha=0.5, density=True)\n",
    "    plt.title(\"Volatility Distribution Classificaiton\")\n",
    "    plt.xlabel(\"y2\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend([f\"Class {i}\" for i in np.unique(df[\"target class\"])])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e7457f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[features].isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8697eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[targets].isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73420aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747303209.581149  437505 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5529 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:07:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,776</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m3,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m24\u001b[0m)         │         \u001b[38;5;34m5,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │         \u001b[38;5;34m1,776\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,867</span> (42.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,867\u001b[0m (42.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,867</span> (42.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,867\u001b[0m (42.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "lookback = 60\n",
    "n_features = len(features)\n",
    "\n",
    "def create_dataset(data, target, lookback=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - lookback):\n",
    "        X.append(data[i:(i + lookback)])\n",
    "        y.append(target[i + lookback])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Input(shape=(lookback, n_features)))\n",
    "model.add(Conv1D(32, 3, activation=\"relu\", padding=\"same\"))\n",
    "\n",
    "model.add(LayerNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(24, return_sequences=True))\n",
    "model.add(LSTM(12, return_sequences=False))\n",
    "\n",
    "model.add(Dense(16, activation=\"relu\"))  \n",
    "model.add(Dropout(0.2))                    \n",
    "\n",
    "if target_type == \"reg\":\n",
    "    model.add(Dense(len(targets), activation=\"linear\")) # log return, vol\n",
    "else:\n",
    "    model.add(Dense(len(np.unique(df[\"target class\"])), activation=\"softmax\")) # class output\n",
    "    \n",
    "if target_type == \"reg\":\n",
    "    metric = \"mape\"\n",
    "    model.compile(optimizer=Adam(3e-4), loss=\"mean_squared_error\", metrics=[metric]) # reg compile\n",
    "else:\n",
    "    metric = \"accuracy\"\n",
    "    model.compile(optimizer=Adam(1e-4), loss=\"sparse_categorical_crossentropy\", metrics=[metric]) # class compile\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2378192b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(\n",
    "    model,\n",
    "    to_file=f\"model_images/{target_type}.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    show_dtype=False,\n",
    "    rankdir=\"TB\",\n",
    "    dpi=96\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97100b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265bdb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184.1875, 23.03125, 23.03125)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "val, test = train_test_split(test, test_size=0.5, shuffle=False)\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "train[features] = feature_scaler.fit_transform(train[features])\n",
    "test[features] = feature_scaler.transform(test[features])\n",
    "val[features] = feature_scaler.transform(val[features])\n",
    "\n",
    "# if target_type == \"reg\":\n",
    "#     target_scaler = StandardScaler()\n",
    "#     train[targets] = target_scaler.fit_transform(train[targets])\n",
    "#     test[targets] = target_scaler.transform(test[targets])\n",
    "#     val[targets] = target_scaler.transform(val[targets])\n",
    "\n",
    "# make sure the data length is divisible by the batch size\n",
    "# train = train.iloc[:len(train) - len(train) % batch_size]\n",
    "# test = test.iloc[:len(test) - len(test) % batch_size]\n",
    "# val = val.iloc[:len(val) - len(val) % batch_size]\n",
    "\n",
    "train.shape[0] / batch_size, test.shape[0] / batch_size, val.shape[0] / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5518d24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.index.max() < val.index.min(), val.index.max() < test.index.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb90ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05cb504",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_dataset(train[features].values, train[targets].values, lookback)\n",
    "X_test, y_test = create_dataset(test[features].values, test[targets].values, lookback)\n",
    "X_val, y_val = create_dataset(val[features].values, val[targets].values, lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e763eb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee70ecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename all class 0 to class 1 in 3 class\n",
    "# y_train[y_train == 0] = 1\n",
    "# y_test[y_test == 0] = 1\n",
    "# y_val[y_val == 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38828a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_type != \"reg\":\n",
    "    # Assuming y_train is your 1D array of class labels\n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train[:,0]\n",
    "    )\n",
    "    # Convert to dictionary format required by Keras\n",
    "    class_weight_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef24262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(y_train[:, 0]), class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd6f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747303212.465879  437748 cuda_dnn.cc:529] Loaded cuDNN version 90701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.5510 - loss: 1.0457 - val_accuracy: 0.7548 - val_loss: 0.8763\n",
      "Epoch 2/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.7532 - loss: 0.8668 - val_accuracy: 0.7637 - val_loss: 0.7346\n",
      "Epoch 3/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7659 - loss: 0.7230 - val_accuracy: 0.7651 - val_loss: 0.6453\n",
      "Epoch 4/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.7807 - loss: 0.6202 - val_accuracy: 0.7563 - val_loss: 0.5882\n",
      "Epoch 5/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - accuracy: 0.7762 - loss: 0.5538 - val_accuracy: 0.7563 - val_loss: 0.5516\n",
      "Epoch 6/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.7766 - loss: 0.5157 - val_accuracy: 0.7622 - val_loss: 0.5262\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7663 - loss: 0.6500\n",
      "Test Loss: 0.6066\n",
      "Test Metric: 0.7784\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor=f\"val_{metric}\", patience=3, restore_best_weights=True)\n",
    "if target_type == \"reg\":\n",
    "    history = model.fit(X_train, y_train, epochs=100, batch_size=batch_size, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=1)\n",
    "else:\n",
    "    history = model.fit(X_train, y_train, epochs=100, batch_size=batch_size, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=1, class_weight=class_weight_dict)\n",
    "    \n",
    "# Evaluate the mode;\n",
    "loss, metric = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Metric: {metric:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be5d578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.828     0.846     0.837       455\n",
      "           1      0.670     0.640     0.654       222\n",
      "\n",
      "    accuracy                          0.778       677\n",
      "   macro avg      0.749     0.743     0.746       677\n",
      "weighted avg      0.776     0.778     0.777       677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "if target_type != \"reg\":\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "else:\n",
    "    from sklearn.metrics import (mean_absolute_error, mean_squared_error,\n",
    "                             mean_absolute_percentage_error, r2_score,\n",
    "                             explained_variance_score)\n",
    "\n",
    "    def regression_report(y_true, y_pred, digits: int = 3):\n",
    "        \"\"\"Return a DataFrame with the main regression metrics.\"\"\"\n",
    "        mae  = mean_absolute_error(y_true, y_pred)\n",
    "        mse  = mean_squared_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "        r2   = r2_score(y_true, y_pred)\n",
    "        evs  = explained_variance_score(y_true, y_pred)\n",
    "\n",
    "        data = {\n",
    "            \"MAE\":  mae,\n",
    "            \"RMSE\": rmse,\n",
    "            \"R²\":   r2,\n",
    "            \"MAPE\": mape,\n",
    "            \"Expl. Var.\": evs\n",
    "        }\n",
    "        return pd.DataFrame(data, index=[\"score\"]).round(digits)\n",
    "\n",
    "    # usage\n",
    "    y_pred = model.predict(X_test).ravel()\n",
    "    report = regression_report(y_test, y_pred)\n",
    "    print(report)\n",
    "\n",
    "    print(f\"Baseline R2: {r2_score(y_test[:-1], y_test[1:])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd1eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(f\"keras_models/{target_type}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623709a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scaler\n",
    "import pickle\n",
    "with open(f\"scalers/{target_type}_features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(feature_scaler, f)\n",
    "\n",
    "# if target_type == \"reg\":\n",
    "#     with open(f\"scalers/{target_type}_target.pkl\", \"wb\") as f:\n",
    "#         pickle.dump(target_scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42164b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
